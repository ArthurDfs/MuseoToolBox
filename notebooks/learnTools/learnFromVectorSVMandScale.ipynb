{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn from vector and compare influence of standardize data in SVM\n",
    "\n",
    "\n",
    "vectorTools to extract values of bands from vector, and to slect a sampling method for Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MuseoToolBox import  learnAndPredict\n",
    "from MuseoToolBox import vectorTools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select an algorithm from sklearn\n",
    "Here we select RandomForestClassifier from sklearn.ensemble\n",
    "We define the param_grid for the Cross-Validation according to the [parameters of RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "param_grid = dict(gamma=2.0**np.arange(-4,1), C=10.0**np.arange(-2,2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inRaster = '../data/map.tif'\n",
    "inVector = '../data/train_withROI.gpkg'\n",
    "inField = 'Class'\n",
    "inStand = 'uniqueFID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Setup the Cross-Validation and extract values from vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Values from vector\n",
    "Y,S,X = vectorTools.readValuesFromVector(inVector,inField,inStand,bandPrefix='band_')\n",
    "# Get random  5000 features in order to faster the test\n",
    "downsampled = np.random.permutation(range(X.shape[0]))[:5000]\n",
    "Y = Y[downsampled]\n",
    "S = S[downsampled]\n",
    "X = X[downsampled,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup learnAndPredict\n",
    "With the algorithm (and its parameters, such as *oob_score=True* if you want to be able to save it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learnAndPredict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "standMethod = vectorTools.samplingMethods.standCV(S,SLOO=False,maxIter=5,seed=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and compare performances between CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with standardized data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best gamma : 1.0\n",
      "best C : 0.1\n",
      "Kappa : 0.911354396688 | OA : 0.953235908142\n",
      "Kappa : 0.842579665241 | OA : 0.902118644068\n",
      "Kappa : 0.890309116058 | OA : 0.939660590823\n",
      "Kappa : 0.846020109451 | OA : 0.906418070993\n",
      "Kappa : 0.860531304038 | OA : 0.916880891174\n",
      "Mean kappa for 5 iter with scale as True : 87.02% (+-2.66)\n",
      "========================================\n",
      "Results with unstandardized data\n",
      "best gamma : 0.0625\n",
      "best C : 10.0\n",
      "Kappa : 0.68292357346 | OA : 0.84885177453\n",
      "Kappa : 0.760907286231 | OA : 0.856779661017\n",
      "Kappa : 0.679636782596 | OA : 0.835637963545\n",
      "Kappa : 0.6828542434 | OA : 0.820007171029\n",
      "Kappa : 0.796223492896 | OA : 0.881748071979\n",
      "Mean kappa for 5 iter with scale as False : 72.05% (+-4.87)\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# initialize learning\n",
    "\n",
    "for scale in [True,False]:\n",
    "    if scale is True:print('Results with standardized data')\n",
    "    else:print('Results with unstandardized data')\n",
    "        \n",
    "    # Generate Cross-Validation from Vector, that's why inField (2nd argument) is None.\n",
    "    standCV = vectorTools.sampleSelection(Y,None,standMethod)\n",
    "    \n",
    "    model.learnFromVector(X,Y,classifier=SVC(),param_grid=param_grid,\\\n",
    "                          scale=scale,cv=standCV.getCrossValidationForScikitLearn())\n",
    "    matrix,kappa,OA=model.getStatsFromCV(kappa=True,OA=True)\n",
    "    \n",
    "    for idx,mtrx in enumerate(matrix):\n",
    "        print('Kappa : '+str(kappa[idx])+' | OA : '+str(OA[idx]))\n",
    "        #print(mtrx)\n",
    "    \n",
    "    meanKappa = round(np.mean(kappa)*100,2)\n",
    "    stdKappa = round(np.std(kappa)*100,2)\n",
    "    print('Mean kappa for 5 iter with scale as {} : {}% (+-{})'.format(scale,meanKappa,stdKappa))\n",
    "    print(40*\"=\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So don't forget to standardize your data when using SVM (SVC for classes).**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
